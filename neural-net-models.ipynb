{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6192b5c",
   "metadata": {
    "papermill": {
     "duration": 0.020803,
     "end_time": "2022-04-23T11:47:28.464642",
     "exception": false,
     "start_time": "2022-04-23T11:47:28.443839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "hello \n",
    "In this notebook, I have taken some of the CNN architectures and tried to implement them layer by layer.\n",
    "I hope it will be useful for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b1affcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:28.516624Z",
     "iopub.status.busy": "2022-04-23T11:47:28.510645Z",
     "iopub.status.idle": "2022-04-23T11:47:35.325939Z",
     "shell.execute_reply": "2022-04-23T11:47:35.325190Z",
     "shell.execute_reply.started": "2022-04-23T11:17:45.393059Z"
    },
    "papermill": {
     "duration": 6.841265,
     "end_time": "2022-04-23T11:47:35.326137",
     "exception": false,
     "start_time": "2022-04-23T11:47:28.484872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    " \n",
    "import cv2\n",
    "import random\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import SpatialDropout2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cbef8",
   "metadata": {
    "papermill": {
     "duration": 0.019038,
     "end_time": "2022-04-23T11:47:35.364621",
     "exception": false,
     "start_time": "2022-04-23T11:47:35.345583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **AlexNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b2474",
   "metadata": {
    "papermill": {
     "duration": 0.019173,
     "end_time": "2022-04-23T11:47:35.403190",
     "exception": false,
     "start_time": "2022-04-23T11:47:35.384017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://miro.medium.com/max/700/1*vXBvV_Unz3JAxytc5iSeoQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca7b3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:35.454141Z",
     "iopub.status.busy": "2022-04-23T11:47:35.453420Z",
     "iopub.status.idle": "2022-04-23T11:47:35.457448Z",
     "shell.execute_reply": "2022-04-23T11:47:35.458012Z",
     "shell.execute_reply.started": "2022-04-23T10:52:12.959170Z"
    },
    "papermill": {
     "duration": 0.035449,
     "end_time": "2022-04-23T11:47:35.458189",
     "exception": false,
     "start_time": "2022-04-23T11:47:35.422740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def alexnet(input_shape):\n",
    "    input = tensorflow.keras.layers.Input(input_shape)\n",
    "    x = tensorflow.keras.layers.Conv2D(96, (11,11), strides=4)(input)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((3,3), strides=2, padding =\"same\")(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(256, (5,5), strides=1, padding =\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((5,5), strides=2, padding =\"same\")(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(384, (3,3), strides=1, padding =\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(384, (3,3), strides=1, padding =\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(256, (3,3), strides=1, padding =\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((3,3), strides=2, padding =\"same\")(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Dense(9216)(x)\n",
    "    x = tensorflow.keras.layers.Dense(4096)(x)\n",
    "    x = tensorflow.keras.layers.Dense(4096)(x)\n",
    "    \n",
    "    model = tensorflow.keras.models.Model(input,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43d68c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:35.499572Z",
     "iopub.status.busy": "2022-04-23T11:47:35.498931Z",
     "iopub.status.idle": "2022-04-23T11:47:36.173668Z",
     "shell.execute_reply": "2022-04-23T11:47:36.173037Z",
     "shell.execute_reply.started": "2022-04-23T10:52:21.248329Z"
    },
    "papermill": {
     "duration": 0.696422,
     "end_time": "2022-04-23T11:47:36.173836",
     "exception": false,
     "start_time": "2022-04-23T11:47:35.477414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,noverbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2022-04-23 11:47:35.549106: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7, 7, 9216)        2368512   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7, 7, 4096)        37752832  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7, 7, 4096)        16781312  \n",
      "=================================================================\n",
      "Total params: 60,649,856\n",
      "Trainable params: 60,649,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (227,227,3)\n",
    "m = alexnet(input_shape)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d9165",
   "metadata": {
    "papermill": {
     "duration": 0.019665,
     "end_time": "2022-04-23T11:47:36.214106",
     "exception": false,
     "start_time": "2022-04-23T11:47:36.194441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **VGG16** \n",
    "![](https://miro.medium.com/max/700/1*1gA7d9svzp_jRHPsyy63Iw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c8041b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:36.257977Z",
     "iopub.status.busy": "2022-04-23T11:47:36.257290Z",
     "iopub.status.idle": "2022-04-23T11:47:36.273822Z",
     "shell.execute_reply": "2022-04-23T11:47:36.274363Z",
     "shell.execute_reply.started": "2022-04-23T10:52:30.678650Z"
    },
    "papermill": {
     "duration": 0.039956,
     "end_time": "2022-04-23T11:47:36.274559",
     "exception": false,
     "start_time": "2022-04-23T11:47:36.234603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg16(input_shape):\n",
    "    input = tensorflow.keras.layers.Input(input_shape)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(64,(3,3),strides=1, padding=\"same\")(input)\n",
    "    x = tensorflow.keras.layers.Conv2D(64,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(128,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(128,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(256,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(256,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(256,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512,(3,3),strides=1, padding=\"same\")(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((2,2),strides=2)(x)\n",
    "    x = tensorflow.keras.layers.Flatten()(x)\n",
    "    x = tensorflow.keras.layers.Dense(4096)(x)\n",
    "    x = tensorflow.keras.layers.Dense(4096)(x)\n",
    "    x = tensorflow.keras.layers.Dense(1000,activation='softmax')(x)\n",
    "  \n",
    "    model = tensorflow.keras.models.Model(input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d471e57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:36.319465Z",
     "iopub.status.busy": "2022-04-23T11:47:36.318692Z",
     "iopub.status.idle": "2022-04-23T11:47:37.517875Z",
     "shell.execute_reply": "2022-04-23T11:47:37.516660Z",
     "shell.execute_reply.started": "2022-04-23T10:52:38.748444Z"
    },
    "papermill": {
     "duration": 1.223283,
     "end_time": "2022-04-23T11:47:37.518143",
     "exception": false,
     "start_time": "2022-04-23T11:47:36.294860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224,3)\n",
    "model = vgg16(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a94246",
   "metadata": {
    "papermill": {
     "duration": 0.020206,
     "end_time": "2022-04-23T11:47:37.559744",
     "exception": false,
     "start_time": "2022-04-23T11:47:37.539538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **GoogleNet/Inception** \n",
    "![](https://cdn-images-1.medium.com/max/1600/1*CWJGqfLiVjHAIan82nPbjg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d29cd62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:37.604721Z",
     "iopub.status.busy": "2022-04-23T11:47:37.603901Z",
     "iopub.status.idle": "2022-04-23T11:47:37.623574Z",
     "shell.execute_reply": "2022-04-23T11:47:37.624146Z",
     "shell.execute_reply.started": "2022-04-23T10:52:46.951431Z"
    },
    "papermill": {
     "duration": 0.044204,
     "end_time": "2022-04-23T11:47:37.624346",
     "exception": false,
     "start_time": "2022-04-23T11:47:37.580142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def googlenet_inception(input_shape):\n",
    "    def inception_block(x,f):\n",
    "        t1 = tensorflow.keras.layers.Conv2D(f[0], 1, activation='relu')(x)\n",
    "        t2 = tensorflow.keras.layers.Conv2D(f[1], 1, activation='relu')(x)\n",
    "        t2 = tensorflow.keras.layers.Conv2D(f[2], 3, padding='same', activation='relu')(t2)\n",
    "        t3 = tensorflow.keras.layers.Conv2D(f[3], 1, activation='relu')(x)\n",
    "        t3 = tensorflow.keras.layers.Conv2D(f[4], 5, padding='same', activation='relu')(t3)\n",
    "        t4 = tensorflow.keras.layers.MaxPooling2D(3, 1, padding='same')(x)\n",
    "        t4 = tensorflow.keras.layers.Conv2D(f[5], 1, activation='relu')(t4)\n",
    "        output = tensorflow.keras.layers.Concatenate()([t1, t2, t3, t4])\n",
    "        return output\n",
    "\n",
    "    input = tensorflow.keras.layers.Input(input_shape)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Conv2D(64, (7,7),strides = 2, padding='same', activation='relu')(input)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((3,3),strides = 2, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(64, (1,1),activation='relu')(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(192, (3,3), padding='same', activation='relu')(x)\n",
    "    x = tensorflow.keras.layers.MaxPooling2D((3,3),strides = 2)(x)\n",
    "    \n",
    "    x = inception_block(x, [64, 96, 128, 16, 32, 32])\n",
    "    x = inception_block(x, [128, 128, 192, 32, 96, 64])\n",
    "    x = tensorflow.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = inception_block(x, [192, 96, 208, 16, 48, 64])\n",
    "    x = inception_block(x, [160, 112, 224, 24, 64, 64])\n",
    "    x = inception_block(x, [128, 128, 256, 24, 64, 64])\n",
    "    x = inception_block(x, [112, 144, 288, 32, 64, 64])\n",
    "    x = inception_block(x, [256, 160, 320, 32, 128, 128])\n",
    "    x = tensorflow.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    x = inception_block(x, [256, 160, 320, 32, 128, 128])\n",
    "    x = inception_block(x, [384, 192, 384, 48, 128, 128])\n",
    "  \n",
    "    x = tensorflow.keras.layers.AveragePooling2D(7, strides=1)(x)\n",
    "    x = tensorflow.keras.layers.Dropout(0.4)(x)\n",
    "  \n",
    "    x = tensorflow.keras.layers.Flatten()(x)\n",
    "    x = tensorflow.keras.layers.Dense(1000, activation='softmax')(x)\n",
    "\n",
    "    \n",
    "    model = tensorflow.keras.models.Model(input,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c93268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:37.669214Z",
     "iopub.status.busy": "2022-04-23T11:47:37.668519Z",
     "iopub.status.idle": "2022-04-23T11:47:38.341523Z",
     "shell.execute_reply": "2022-04-23T11:47:38.340601Z",
     "shell.execute_reply.started": "2022-04-23T10:52:56.309965Z"
    },
    "papermill": {
     "duration": 0.69627,
     "end_time": "2022-04-23T11:47:38.341719",
     "exception": false,
     "start_time": "2022-04-23T11:47:37.645449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 227, 227, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 114, 114, 64) 9472        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 57, 57, 64)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 57, 57, 64)   4160        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 57, 57, 192)  110784      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 28, 28, 192)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 96)   18528       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 16)   3088        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 28, 28, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 64)   12352       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 128)  110720      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 28, 32)   12832       conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 28, 28, 32)   6176        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 256)  0           conv2d_21[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 32)   8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 28, 28, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 28, 28, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 192)  221376      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 28, 28, 96)   76896       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 28, 28, 64)   16448       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 480)  0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 14, 14, 480)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 96)   46176       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 16)   7696        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 14, 14, 480)  0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 192)  92352       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 208)  179920      conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 48)   19248       conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 64)   30784       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 512)  0           conv2d_33[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 112)  57456       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 24)   12312       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 14, 14, 512)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 160)  82080       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 224)  226016      conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 64)   38464       conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 14, 14, 512)  0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 128)  65664       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 24)   12312       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 14, 14, 512)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 128)  65664       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 256)  295168      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 64)   38464       conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 14, 14, 512)  0           conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 144)  73872       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 32)   16416       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 14, 14, 512)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 112)  57456       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 288)  373536      conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 64)   51264       conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 14, 14, 528)  0           conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 160)  84640       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 32)   16928       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 14, 14, 528)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 256)  135424      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 320)  461120      conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 128)  102528      conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 128)  67712       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 14, 14, 832)  0           conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 7, 7, 832)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 160)    133280      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 32)     26656       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 7, 7, 832)    0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 256)    213248      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 320)    461120      conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 128)    102528      conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 7, 7, 832)    0           conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    159936      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 48)     39984       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 7, 7, 832)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 384)    319872      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 384)    663936      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 128)    153728      conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 128)    106624      max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 7, 7, 1024)   0           conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 1024)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 1, 1024)   0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1000)         1025000     flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,998,552\n",
      "Trainable params: 6,998,552\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (227,227,3)\n",
    "model = googlenet_inception(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada35a9e",
   "metadata": {
    "papermill": {
     "duration": 0.020865,
     "end_time": "2022-04-23T11:47:38.384068",
     "exception": false,
     "start_time": "2022-04-23T11:47:38.363203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **MobileNet**\n",
    "![](https://miro.medium.com/max/856/1*2IHiEn6SYGgz-p80jhYeGg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c45e813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:38.444901Z",
     "iopub.status.busy": "2022-04-23T11:47:38.443728Z",
     "iopub.status.idle": "2022-04-23T11:47:38.472497Z",
     "shell.execute_reply": "2022-04-23T11:47:38.471890Z",
     "shell.execute_reply.started": "2022-04-23T10:53:08.800991Z"
    },
    "papermill": {
     "duration": 0.067218,
     "end_time": "2022-04-23T11:47:38.472645",
     "exception": false,
     "start_time": "2022-04-23T11:47:38.405427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MobileNet(input_shape, nb_classes):\n",
    "    input = tensorflow.keras.layers.Input(input_shape)\n",
    "    x = tensorflow.keras.layers.Conv2D(32, (3,3), strides=2, padding =\"same\")(input)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(64, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(128, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(128, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(256, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(256, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "     # five blocks\n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(512, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # end five blocks\n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=2, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(1024, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    \n",
    "    x = tensorflow.keras.layers.DepthwiseConv2D((3,3), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    x = tensorflow.keras.layers.Conv2D(1024, (1,1), strides=1, padding='same')(x)\n",
    "    x = tensorflow.keras.layers.BatchNormalization()(x)\n",
    "    x = tensorflow.keras.layers.ReLU()(x)\n",
    "    \n",
    "    \n",
    "    x = tensorflow.keras.layers.GlobalAvgPool2D()(x)\n",
    "    output = Dense(nb_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tensorflow.keras.models.Model(input,output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d5867f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:38.524421Z",
     "iopub.status.busy": "2022-04-23T11:47:38.523069Z",
     "iopub.status.idle": "2022-04-23T11:47:39.139751Z",
     "shell.execute_reply": "2022-04-23T11:47:39.140618Z",
     "shell.execute_reply.started": "2022-04-23T10:53:17.769790Z"
    },
    "papermill": {
     "duration": 0.647116,
     "end_time": "2022-04-23T11:47:39.140887",
     "exception": false,
     "start_time": "2022-04-23T11:47:38.493771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 112, 112, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 56, 56, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 56, 56, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 56, 56, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 56, 56, 128)       16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 28, 28, 256)       33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 28, 28, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 28, 28, 256)       65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 14, 14, 256)       2560      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 14, 14, 512)       131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 14, 14, 512)       5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 7, 7, 512)         5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 7, 7, 1024)        525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 7, 7, 1024)        10240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 7, 7, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              1025000   \n",
      "=================================================================\n",
      "Total params: 4,264,808\n",
      "Trainable params: 4,242,920\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224,224,3)\n",
    "model = MobileNet(input_shape,1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd18049",
   "metadata": {
    "papermill": {
     "duration": 0.021855,
     "end_time": "2022-04-23T11:47:39.186469",
     "exception": false,
     "start_time": "2022-04-23T11:47:39.164614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **ResNet 50**\n",
    "![](https://iq.opengenus.org/content/images/2020/03/Screenshot-from-2020-03-20-15-49-54.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2655b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:39.242773Z",
     "iopub.status.busy": "2022-04-23T11:47:39.235298Z",
     "iopub.status.idle": "2022-04-23T11:47:39.321633Z",
     "shell.execute_reply": "2022-04-23T11:47:39.322177Z",
     "shell.execute_reply.started": "2022-04-23T10:53:26.684583Z"
    },
    "papermill": {
     "duration": 0.113928,
     "end_time": "2022-04-23T11:47:39.322377",
     "exception": false,
     "start_time": "2022-04-23T11:47:39.208449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ResNet model creation\n",
    "def ResNet50(input_w,input_h):\n",
    "  if tensorflow.keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, input_w, input_h)\n",
    "  else:\n",
    "    input_shape = (input_w, input_h,3)\n",
    "\n",
    " \n",
    "  model_input = tensorflow.keras.layers.Input(shape=input_shape)\n",
    "  \n",
    " \n",
    "  ########### Block 1 ###########\n",
    "  block_1 = tensorflow.keras.layers.Conv2D(64,kernel_size=7,strides=2, padding='same')(model_input)\n",
    "  block_1 = tensorflow.keras.layers.BatchNormalization()(block_1)\n",
    "  block_1 = tensorflow.keras.layers.ReLU()(block_1)\n",
    "  block_1 = tensorflow.keras.layers.MaxPooling2D(3, strides=2, padding='same')(block_1)\n",
    " ############ Block 2 #############\n",
    " ### conv_block ###\n",
    "  block_2_1 = tensorflow.keras.layers.BatchNormalization()(block_1)\n",
    "  block_2_1 = tensorflow.keras.layers.ReLU()(block_2_1)\n",
    "  block_2_1 = tensorflow.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_1)\n",
    "  \n",
    "  block_2_1 = tensorflow.keras.layers.BatchNormalization()(block_2_1)\n",
    "  block_2_1 = tensorflow.keras.layers.ReLU()(block_2_1)\n",
    "  block_2_1 = tensorflow.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_1)\n",
    "  \n",
    "  block_2_1 = tensorflow.keras.layers.BatchNormalization()(block_2_1)\n",
    "  block_2_1 = tensorflow.keras.layers.ReLU()(block_2_1)\n",
    "  block_2_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_1)\n",
    "\n",
    "  sh_cut_2 = tensorflow.keras.layers.BatchNormalization()(block_1)\n",
    "  sh_cut_2 = tensorflow.keras.layers.ReLU()(sh_cut_2)\n",
    "  sh_cut_2 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(sh_cut_2)\n",
    "\n",
    "  stg1_blok_2_1 = tensorflow.keras.layers.add([sh_cut_2, block_2_1])\n",
    "  ### identity_block 1 ###\n",
    "  block_2_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_2_1)\n",
    "  block_2_2 = tensorflow.keras.layers.ReLU()(block_2_2)\n",
    "  block_2_2 = tensorflow.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_2)\n",
    "  \n",
    "  block_2_2 = tensorflow.keras.layers.BatchNormalization()(block_2_2)\n",
    "  block_2_2 = tensorflow.keras.layers.ReLU()(block_2_2)\n",
    "  block_2_2 = tensorflow.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_2)\n",
    "  \n",
    "  block_2_2 = tensorflow.keras.layers.BatchNormalization()(block_2_2)\n",
    "  block_2_2 = tensorflow.keras.layers.ReLU()(block_2_2)\n",
    "  block_2_2 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_2)\n",
    "\n",
    "  stg1_blok_2_2 = tensorflow.keras.layers.add([stg1_blok_2_1, block_2_2])\n",
    "\n",
    "  ### identity_block 2 ###\n",
    "  block_2_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_2_2)\n",
    "  block_2_3 = tensorflow.keras.layers.ReLU()(block_2_3)\n",
    "  block_2_3 = tensorflow.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_3)\n",
    "  \n",
    "  block_2_3 = tensorflow.keras.layers.BatchNormalization()(block_2_3)\n",
    "  block_2_3 = tensorflow.keras.layers.ReLU()(block_2_3)\n",
    "  block_2_3 = tensorflow.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_3)\n",
    "  \n",
    "  block_2_3 = tensorflow.keras.layers.BatchNormalization()(block_2_3)\n",
    "  block_2_3 = tensorflow.keras.layers.ReLU()(block_2_3)\n",
    "  block_2_3 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_3)\n",
    "\n",
    "  stg1_blok_2_3 = tensorflow.keras.layers.add([stg1_blok_2_2, block_2_3])\n",
    "\n",
    "  block_1 = tensorflow.keras.layers.BatchNormalization()(block_1)\n",
    "  block_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_1)\n",
    "\n",
    "  short_cut_2 = tensorflow.keras.layers.add([stg1_blok_2_3, block_1])\n",
    "\n",
    "############ Block 3 #############\n",
    "  ### 1 : conv_block ###\n",
    "  block_3_1 = tensorflow.keras.layers.BatchNormalization()(short_cut_2)\n",
    "  block_3_1 = tensorflow.keras.layers.ReLU()(block_3_1)\n",
    "  block_3_1 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_1)\n",
    "  \n",
    "  block_3_1 = tensorflow.keras.layers.BatchNormalization()(block_3_1)\n",
    "  block_3_1 = tensorflow.keras.layers.ReLU()(block_3_1)\n",
    "  block_3_1 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_1)\n",
    "  \n",
    "  block_3_1 = tensorflow.keras.layers.BatchNormalization()(block_3_1)\n",
    "  block_3_1 = tensorflow.keras.layers.ReLU()(block_3_1)\n",
    "  block_3_1 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_1)\n",
    "\n",
    "  sh_cut_3 = tensorflow.keras.layers.BatchNormalization()(short_cut_2)\n",
    "  sh_cut_3 = tensorflow.keras.layers.ReLU()(sh_cut_3)\n",
    "  sh_cut_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(sh_cut_3)\n",
    "\n",
    "  stg1_blok_3_1 = tensorflow.keras.layers.add([sh_cut_3, block_3_1])\n",
    "  ### 2 : identity_block  ###\n",
    "  block_3_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_3_1)\n",
    "  block_3_2 = tensorflow.keras.layers.ReLU()(block_3_2)\n",
    "  block_3_2 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_2)\n",
    "  \n",
    "  block_3_2 = tensorflow.keras.layers.BatchNormalization()(block_3_2)\n",
    "  block_3_2 = tensorflow.keras.layers.ReLU()(block_3_2)\n",
    "  block_3_2 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_2)\n",
    "  \n",
    "  block_3_2 = tensorflow.keras.layers.BatchNormalization()(block_3_2)\n",
    "  block_3_2 = tensorflow.keras.layers.ReLU()(block_3_2)\n",
    "  block_3_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_2)\n",
    "\n",
    "  stg1_blok_3_2 = tensorflow.keras.layers.add([stg1_blok_3_1, block_3_2])\n",
    "\n",
    "  ### 3 : identity_block  ###\n",
    "  block_3_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_3_2)\n",
    "  block_3_3 = tensorflow.keras.layers.ReLU()(block_3_3)\n",
    "  block_3_3 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_3)\n",
    "  \n",
    "  block_3_3 = tensorflow.keras.layers.BatchNormalization()(block_3_3)\n",
    "  block_3_3 = tensorflow.keras.layers.ReLU()(block_3_3)\n",
    "  block_3_3 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_3)\n",
    "  \n",
    "  block_3_3 = tensorflow.keras.layers.BatchNormalization()(block_3_3)\n",
    "  block_3_3 = tensorflow.keras.layers.ReLU()(block_3_3)\n",
    "  block_3_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_3)\n",
    "  stg1_blok_3_3 = tensorflow.keras.layers.add([stg1_blok_3_2, block_3_3])\n",
    "\n",
    " \n",
    "  \n",
    "\n",
    "  ### 4:identity_block  ###\n",
    "  block_3_4 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_3_3)\n",
    "  block_3_4 = tensorflow.keras.layers.ReLU()(block_3_4)\n",
    "  block_3_4 = tensorflow.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_4)\n",
    "  \n",
    "  block_3_4 = tensorflow.keras.layers.BatchNormalization()(block_3_4)\n",
    "  block_3_4 = tensorflow.keras.layers.ReLU()(block_3_4)\n",
    "  block_3_4 = tensorflow.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_4)\n",
    "  \n",
    "  block_3_4 = tensorflow.keras.layers.BatchNormalization()(block_3_4)\n",
    "  block_3_4 = tensorflow.keras.layers.ReLU()(block_3_4)\n",
    "  block_3_4 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_4)\n",
    "\n",
    "  stg1_blok_3_4 = tensorflow.keras.layers.add([stg1_blok_3_3, block_3_4])\n",
    "\n",
    "  short_cut_2 = tensorflow.keras.layers.BatchNormalization()(short_cut_2)\n",
    "  short_cut_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(short_cut_2)\n",
    "\n",
    "  short_cut_3 = tensorflow.keras.layers.add([stg1_blok_3_4, short_cut_2])\n",
    "\n",
    "\n",
    "############ Block 4 #############\n",
    "  ### 1 : conv_block ###\n",
    "  block_4_1 = tensorflow.keras.layers.BatchNormalization()(short_cut_3)\n",
    "  block_4_1 = tensorflow.keras.layers.ReLU()(block_4_1)\n",
    "  block_4_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_1)\n",
    "  \n",
    "  block_4_1 = tensorflow.keras.layers.BatchNormalization()(block_4_1)\n",
    "  block_4_1 = tensorflow.keras.layers.ReLU()(block_4_1)\n",
    "  block_4_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_1)\n",
    "  \n",
    "  block_4_1 = tensorflow.keras.layers.BatchNormalization()(block_4_1)\n",
    "  block_4_1 = tensorflow.keras.layers.ReLU()(block_4_1)\n",
    "  block_4_1 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_1)\n",
    "\n",
    "  sh_cut_4 = tensorflow.keras.layers.BatchNormalization()(short_cut_3)\n",
    "  sh_cut_4 = tensorflow.keras.layers.ReLU()(sh_cut_4)\n",
    "  sh_cut_4 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(sh_cut_4)\n",
    "\n",
    "  stg1_blok_4_1 = tensorflow.keras.layers.add([sh_cut_4, block_4_1])\n",
    "\n",
    "  ### 2 :identity_block  ###\n",
    "  block_4_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_1)\n",
    "  block_4_2 = tensorflow.keras.layers.ReLU()(block_4_2)\n",
    "  block_4_1 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_2)\n",
    "  \n",
    "  block_4_2 = tensorflow.keras.layers.BatchNormalization()(block_4_2)\n",
    "  block_4_2 = tensorflow.keras.layers.ReLU()(block_4_2)\n",
    "  block_4_2 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_2)\n",
    "  \n",
    "  block_4_2 = tensorflow.keras.layers.BatchNormalization()(block_4_2)\n",
    "  block_4_2 = tensorflow.keras.layers.ReLU()(block_4_2)\n",
    "  block_4_2 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_2)\n",
    "  stg1_blok_4_2 = tensorflow.keras.layers.add([stg1_blok_4_1, block_4_2])\n",
    "\n",
    "  ### 3 : identity_block  ###\n",
    "  block_4_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_2)\n",
    "  block_4_3 = tensorflow.keras.layers.ReLU()(block_4_3)\n",
    "  block_4_3 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_3)\n",
    "  \n",
    "  block_4_3 = tensorflow.keras.layers.BatchNormalization()(block_4_3)\n",
    "  block_4_3 = tensorflow.keras.layers.ReLU()(block_4_3)\n",
    "  block_4_3 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_3)\n",
    "  \n",
    "  block_4_3 = tensorflow.keras.layers.BatchNormalization()(block_4_3)\n",
    "  block_4_3 = tensorflow.keras.layers.ReLU()(block_4_3)\n",
    "  block_4_3 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_3)\n",
    "  stg1_blok_4_3 = tensorflow.keras.layers.add([stg1_blok_4_2, block_4_3])\n",
    "\n",
    "  ### 4 : identity_block  ###\n",
    "  block_4_4 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_3)\n",
    "  block_4_4 = tensorflow.keras.layers.ReLU()(block_4_4)\n",
    "  block_4_4 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_4)\n",
    "  \n",
    "  block_4_4 = tensorflow.keras.layers.BatchNormalization()(block_4_4)\n",
    "  block_4_4 = tensorflow.keras.layers.ReLU()(block_4_4)\n",
    "  block_4_4 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_4)\n",
    "  \n",
    "  block_4_4 = tensorflow.keras.layers.BatchNormalization()(block_4_4)\n",
    "  block_4_4 = tensorflow.keras.layers.ReLU()(block_4_4)\n",
    "  block_4_4 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_4)\n",
    "  stg1_blok_4_4 = tensorflow.keras.layers.add([stg1_blok_4_3, block_4_4])\n",
    "\n",
    "  ### 5 : :identity_block  ###\n",
    "  block_4_5 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_4_4)\n",
    "  block_4_5 = tensorflow.keras.layers.ReLU()(block_4_5)\n",
    "  block_4_5 = tensorflow.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_5)\n",
    "  \n",
    "  block_4_5 = tensorflow.keras.layers.BatchNormalization()(block_4_5)\n",
    "  block_4_5 = tensorflow.keras.layers.ReLU()(block_4_5)\n",
    "  block_4_5 = tensorflow.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_5)\n",
    "  \n",
    "  block_4_5 = tensorflow.keras.layers.BatchNormalization()(block_4_5)\n",
    "  block_4_5 = tensorflow.keras.layers.ReLU()(block_4_5)\n",
    "  block_4_5 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_5)\n",
    "  stg1_blok_4_5 = tensorflow.keras.layers.add([stg1_blok_4_4, block_4_5])\n",
    "\n",
    "\n",
    "  short_cut_3 = tensorflow.keras.layers.BatchNormalization()(short_cut_3)\n",
    "  short_cut_3 = tensorflow.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(short_cut_3)\n",
    "\n",
    "  short_cut_4 = tensorflow.keras.layers.add([stg1_blok_4_5, short_cut_3])\n",
    "\n",
    "############ Block 5 #############\n",
    "  ### conv_block ###\n",
    "  block_5_1 = tensorflow.keras.layers.BatchNormalization()(short_cut_4)\n",
    "  block_5_1 = tensorflow.keras.layers.ReLU()(block_5_1)\n",
    "  block_5_1 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_1)\n",
    "  \n",
    "  block_5_1 = tensorflow.keras.layers.BatchNormalization()(block_5_1)\n",
    "  block_5_1 = tensorflow.keras.layers.ReLU()(block_5_1)\n",
    "  block_5_1 = tensorflow.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_1)\n",
    "  \n",
    "  block_5_1 = tensorflow.keras.layers.BatchNormalization()(block_5_1)\n",
    "  block_5_1 = tensorflow.keras.layers.ReLU()(block_5_1)\n",
    "  block_5_1 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_1)\n",
    "\n",
    "  sh_cut_5 = tensorflow.keras.layers.BatchNormalization()(short_cut_4)\n",
    "  sh_cut_5 = tensorflow.keras.layers.ReLU()(sh_cut_5)\n",
    "  sh_cut_5 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(sh_cut_5)\n",
    "\n",
    "  stg1_blok_5_1 = tensorflow.keras.layers.add([sh_cut_5, block_5_1])\n",
    "  ### identity_block 1 ###\n",
    "  block_5_2 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_5_1)\n",
    "  block_5_2 = tensorflow.keras.layers.ReLU()(block_5_2)\n",
    "  block_5_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_2)\n",
    "  \n",
    "  block_5_2 = tensorflow.keras.layers.BatchNormalization()(block_5_2)\n",
    "  block_5_2 = tensorflow.keras.layers.ReLU()(block_5_2)\n",
    "  block_5_2 = tensorflow.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_2)\n",
    "  \n",
    "  block_5_2 = tensorflow.keras.layers.BatchNormalization()(block_5_2)\n",
    "  block_5_2 = tensorflow.keras.layers.ReLU()(block_5_2)\n",
    "  block_5_2 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_2)\n",
    "\n",
    "  stg1_blok_5_2 = tensorflow.keras.layers.add([stg1_blok_5_1, block_5_2])\n",
    "\n",
    "  ### identity_block 2 ###\n",
    "  block_5_3 = tensorflow.keras.layers.BatchNormalization()(stg1_blok_5_2)\n",
    "  block_5_3 = tensorflow.keras.layers.ReLU()(block_5_3)\n",
    "  block_5_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_3)\n",
    "  \n",
    "  block_5_3 = tensorflow.keras.layers.BatchNormalization()(block_5_3)\n",
    "  block_5_3 = tensorflow.keras.layers.ReLU()(block_5_3)\n",
    "  block_5_3 = tensorflow.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_3)\n",
    "  \n",
    "  block_5_3 = tensorflow.keras.layers.BatchNormalization()(block_5_3)\n",
    "  block_5_3 = tensorflow.keras.layers.ReLU()(block_5_3)\n",
    "  block_5_3 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_3)\n",
    "\n",
    "  stg1_blok_5_3 = tensorflow.keras.layers.add([stg1_blok_5_2, block_5_3])\n",
    "\n",
    "  short_cut_4 = tensorflow.keras.layers.BatchNormalization()(short_cut_4)\n",
    "  short_cut_4 = tensorflow.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(short_cut_4)\n",
    "\n",
    "  short_cut_5 = tensorflow.keras.layers.add([stg1_blok_5_3, short_cut_4])\n",
    "############ Block 6 #############\n",
    "  \n",
    "  pooling = tensorflow.keras.layers.GlobalAveragePooling2D()(short_cut_5)\n",
    "  model_output = tensorflow.keras.layers.Dense(5,activation='softmax')(pooling)\n",
    "  \n",
    "  model = tensorflow.keras.models.Model(model_input,model_output)\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01fc4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:39.374528Z",
     "iopub.status.busy": "2022-04-23T11:47:39.373807Z",
     "iopub.status.idle": "2022-04-23T11:47:40.727792Z",
     "shell.execute_reply": "2022-04-23T11:47:40.728432Z",
     "shell.execute_reply.started": "2022-04-23T10:53:40.757976Z"
    },
    "papermill": {
     "duration": 1.384339,
     "end_time": "2022-04-23T11:47:40.728633",
     "exception": false,
     "start_time": "2022-04-23T11:47:39.344294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 128, 128, 64) 9472        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 64) 256         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 128, 128, 64) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 64, 64, 64)   0           re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 64, 64)   256         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 64, 64, 64)   4160        re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 64)   256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 64)   256         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 64, 64, 256)  16640       re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 64, 64, 256)  16640       re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 256)  0           conv2d_93[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 256)  1024        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 64, 64, 64)   16448       re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 64, 64)   256         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 64, 64)   256         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 64, 64, 256)  16640       re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           add[0][0]                        \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 256)  1024        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 64, 64, 64)   16448       re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64, 64, 64)   256         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 64, 64, 64)   256         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 64, 64, 256)  16640       re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 64, 64, 64)   256         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 64, 64, 256)  16640       batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 64, 64, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 64, 64, 128)  32896       re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 64, 64, 128)  512         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 64, 64, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 64, 64, 128)  512         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 64, 64, 512)  131584      re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 64, 64, 512)  66048       re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 512)  0           conv2d_104[0][0]                 \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 64, 64, 512)  2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 64, 64, 128)  65664       re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 64, 64, 128)  512         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 64, 64, 128)  512         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 64, 64, 512)  66048       re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 512)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 64, 64, 512)  2048        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 64, 64, 128)  65664       re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 64, 64, 128)  512         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 64, 64, 128)  512         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 512)  66048       re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 512)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 64, 64, 512)  2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 64, 64, 128)  65664       re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 64, 64, 128)  512         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 64, 64, 128)  147584      re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 64, 64, 128)  512         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 64, 64, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 64, 64, 512)  66048       re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 64, 64, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 512)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 64, 64, 512)  131584      batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 512)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 64, 64, 512)  2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 64, 64, 256)  131328      re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 64, 64, 256)  1024        conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_52 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 64, 64, 256)  590080      re_lu_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 64, 64, 512)  2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 64, 64, 256)  1024        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_54 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_53 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 64, 64, 1024) 525312      re_lu_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 64, 64, 1024) 263168      re_lu_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 64, 1024) 0           conv2d_118[0][0]                 \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 64, 64, 1024) 4096        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_55 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 64, 64, 1024) 4096        re_lu_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_56 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 64, 64, 256)  2359552     re_lu_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 64, 64, 256)  1024        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_57 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 64, 64, 1024) 263168      re_lu_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 64, 1024) 0           add_9[0][0]                      \n",
      "                                                                 conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 64, 64, 1024) 4096        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_58 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 64, 64, 256)  262400      re_lu_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 64, 64, 256)  1024        conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_59 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 64, 64, 256)  590080      re_lu_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 64, 64, 256)  1024        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_60 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 64, 64, 1024) 263168      re_lu_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 64, 1024) 0           add_10[0][0]                     \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 64, 64, 1024) 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 256)  262400      re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 64, 64, 256)  1024        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_62 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 256)  590080      re_lu_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 64, 64, 256)  1024        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_63 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 1024) 263168      re_lu_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 64, 1024) 0           add_11[0][0]                     \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 64, 64, 1024) 4096        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_64 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 256)  262400      re_lu_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 64, 64, 256)  1024        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_65 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 256)  590080      re_lu_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64, 64, 256)  1024        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_66 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 64, 64, 1024) 263168      re_lu_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 64, 64, 512)  2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 64, 1024) 0           add_12[0][0]                     \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 64, 64, 1024) 525312      batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 64, 64, 1024) 0           add_13[0][0]                     \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 64, 64, 1024) 4096        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_67 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 64, 64, 512)  524800      re_lu_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 64, 64, 512)  2048        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_68 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 64, 64, 512)  2359808     re_lu_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 64, 64, 1024) 4096        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 64, 64, 512)  2048        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_70 (ReLU)                 (None, 64, 64, 1024) 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_69 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 64, 64, 2048) 2099200     re_lu_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 64, 64, 2048) 1050624     re_lu_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 64, 64, 2048) 0           conv2d_135[0][0]                 \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 64, 64, 2048) 8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_71 (ReLU)                 (None, 64, 64, 2048) 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 64, 64, 512)  1049088     re_lu_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 64, 64, 512)  2048        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_72 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 64, 64, 512)  2359808     re_lu_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 64, 64, 512)  2048        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_73 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 64, 64, 2048) 1050624     re_lu_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 64, 64, 2048) 0           add_15[0][0]                     \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 64, 64, 2048) 8192        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_74 (ReLU)                 (None, 64, 64, 2048) 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 64, 64, 512)  1049088     re_lu_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 64, 64, 512)  2048        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_75 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 64, 64, 512)  2359808     re_lu_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 64, 64, 512)  2048        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_76 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 64, 64, 2048) 1050624     re_lu_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 64, 64, 1024) 4096        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 64, 64, 2048) 0           add_16[0][0]                     \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 64, 64, 2048) 2099200     batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 64, 64, 2048) 0           add_17[0][0]                     \n",
      "                                                                 conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 5)            10245       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 26,750,597\n",
      "Trainable params: 26,703,237\n",
      "Non-trainable params: 47,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_w = 256\n",
    "image_h = 256\n",
    "n_classes = 5\n",
    "model = ResNet50(image_w,image_h)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75174c",
   "metadata": {
    "papermill": {
     "duration": 0.024314,
     "end_time": "2022-04-23T11:47:40.779756",
     "exception": false,
     "start_time": "2022-04-23T11:47:40.755442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **U-Net**\n",
    "![](https://datascientest.com/wp-content/uploads/2021/05/u-net-architecture-1024x682.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c372f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:40.865955Z",
     "iopub.status.busy": "2022-04-23T11:47:40.861535Z",
     "iopub.status.idle": "2022-04-23T11:47:40.869221Z",
     "shell.execute_reply": "2022-04-23T11:47:40.868522Z",
     "shell.execute_reply.started": "2022-04-23T10:53:53.827391Z"
    },
    "papermill": {
     "duration": 0.066324,
     "end_time": "2022-04-23T11:47:40.869409",
     "exception": false,
     "start_time": "2022-04-23T11:47:40.803085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def UNet(nb_classes, input_shape):\n",
    "    \n",
    "    input = tensorflow.keras.layers.Input(input_shape)\n",
    "    \n",
    "    c1 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(input)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.ReLU()(c1)\n",
    "    \n",
    "    c1 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(c1)\n",
    "    c1 = tensorflow.keras.layers.BatchNormalization()(c1)\n",
    "    c1 = tensorflow.keras.layers.ReLU()(c1)\n",
    "    \n",
    "    p1 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c1)\n",
    "    \n",
    "    c2 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(p1)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.ReLU()(c2)\n",
    "\n",
    "    c2 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(c2)\n",
    "    c2 = tensorflow.keras.layers.BatchNormalization()(c2)\n",
    "    c2 = tensorflow.keras.layers.ReLU()(c2)\n",
    "    \n",
    "    p2 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c2)\n",
    "    \n",
    "    c3 = tensorflow.keras.layers.Conv2D(256, (3,3) ,strides= 1)(p2)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.ReLU()(c3)\n",
    "\n",
    "    c3 = tensorflow.keras.layers.Conv2D(256, (3,3) , strides=1)(c3)\n",
    "    c3 = tensorflow.keras.layers.BatchNormalization()(c3)\n",
    "    c3 = tensorflow.keras.layers.ReLU()(c3)\n",
    "    \n",
    "    p3 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c3)\n",
    "    \n",
    "    c4 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(p3)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.ReLU()(c4)\n",
    "\n",
    "    c4 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(c4)\n",
    "    c4 = tensorflow.keras.layers.BatchNormalization()(c4)\n",
    "    c4 = tensorflow.keras.layers.ReLU()(c4)\n",
    "    \n",
    "    \n",
    "    p4 = tensorflow.keras.layers.MaxPool2D(2, strides=2)(c4)\n",
    "    \n",
    "    c5 = tensorflow.keras.layers.Conv2D(1024, (3,3), strides=1)(p4)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.ReLU()(c5)\n",
    "\n",
    "    c5 = tensorflow.keras.layers.Conv2D(1024, (3,3), strides=1)(c5)\n",
    "    c5 = tensorflow.keras.layers.BatchNormalization()(c5)\n",
    "    c5 = tensorflow.keras.layers.ReLU()(c5)\n",
    "    \n",
    "    \n",
    "    c6 = tensorflow.keras.layers.Conv2DTranspose(1024,(2,2), strides=2)(c5)\n",
    "    u1 = tensorflow.image.resize(c4, ((np.shape(c6)[1]), (np.shape(c6)[2])))\n",
    "    c6 = tensorflow.keras.layers.concatenate([u1,c6])\n",
    "    \n",
    "    c6 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(c6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.ReLU()(c6)\n",
    "\n",
    "    c6 = tensorflow.keras.layers.Conv2D(512, (3,3), strides=1)(c6)\n",
    "    c6 = tensorflow.keras.layers.BatchNormalization()(c6)\n",
    "    c6 = tensorflow.keras.layers.ReLU()(c6)\n",
    "    \n",
    "    c7 = tensorflow.keras.layers.Conv2DTranspose(512,(2,2), strides=2)(c6)\n",
    "    u2 = tensorflow.image.resize(c3, ((np.shape(c7)[1]), (np.shape(c7)[2])))\n",
    "    c7 = tensorflow.keras.layers.concatenate([u2,c7])\n",
    "    \n",
    "    c7 = tensorflow.keras.layers.Conv2D(256, (3,3), strides=1)(c7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.ReLU()(c7)\n",
    "\n",
    "    c7 = tensorflow.keras.layers.Conv2D(256, (3,3), strides=1)(c7)\n",
    "    c7 = tensorflow.keras.layers.BatchNormalization()(c7)\n",
    "    c7 = tensorflow.keras.layers.ReLU()(c7)\n",
    "    \n",
    "    c8 = tensorflow.keras.layers.Conv2DTranspose(256,(2,2), strides=2)(c7)\n",
    "    u3 = tensorflow.image.resize(c2, ((np.shape(c8)[1]), (np.shape(c8)[2])))\n",
    "    c8 = tensorflow.keras.layers.concatenate([u3,c8])\n",
    "    \n",
    "    c8 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(c8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.ReLU()(c8)\n",
    "\n",
    "    c8 = tensorflow.keras.layers.Conv2D(128, (3,3), strides=1)(c8)\n",
    "    c8 = tensorflow.keras.layers.BatchNormalization()(c8)\n",
    "    c8 = tensorflow.keras.layers.ReLU()(c8)\n",
    "    \n",
    "    c9 = tensorflow.keras.layers.Conv2DTranspose(128,(2,2), strides=2)(c8)\n",
    "    u4 = tensorflow.image.resize(c1, ((np.shape(c9)[1]), (np.shape(c9)[2])))\n",
    "    c9 = tensorflow.keras.layers.concatenate([u4,c9])\n",
    "    \n",
    "    c9 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.ReLU()(c9)\n",
    "\n",
    "    c9 = tensorflow.keras.layers.Conv2D(64, (3,3), strides=1)(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.ReLU()(c9)\n",
    "    \n",
    "    c9 = tensorflow.keras.layers.Conv2D(2, (1,1), strides=1)(c9)\n",
    "    c9 = tensorflow.keras.layers.BatchNormalization()(c9)\n",
    "    c9 = tensorflow.keras.layers.ReLU()(c9)\n",
    "    \n",
    "    model = tensorflow.keras.models.Model(input,c9)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa52d6c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:40.929672Z",
     "iopub.status.busy": "2022-04-23T11:47:40.928946Z",
     "iopub.status.idle": "2022-04-23T11:47:41.666810Z",
     "shell.execute_reply": "2022-04-23T11:47:41.666209Z",
     "shell.execute_reply.started": "2022-04-23T10:54:02.695590Z"
    },
    "papermill": {
     "duration": 0.770622,
     "end_time": "2022-04-23T11:47:41.666953",
     "exception": false,
     "start_time": "2022-04-23T11:47:40.896331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 572, 572, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 570, 570, 64) 640         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 570, 570, 64) 256         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_77 (ReLU)                 (None, 570, 570, 64) 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 568, 568, 64) 36928       re_lu_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 568, 568, 64) 256         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_78 (ReLU)                 (None, 568, 568, 64) 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 284, 284, 64) 0           re_lu_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 282, 282, 128 73856       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 282, 282, 128 512         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_79 (ReLU)                 (None, 282, 282, 128 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 280, 280, 128 147584      re_lu_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 280, 280, 128 512         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_80 (ReLU)                 (None, 280, 280, 128 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 140, 140, 128 0           re_lu_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 138, 138, 256 295168      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 138, 138, 256 1024        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_81 (ReLU)                 (None, 138, 138, 256 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 136, 136, 256 590080      re_lu_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 136, 136, 256 1024        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_82 (ReLU)                 (None, 136, 136, 256 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 68, 68, 256)  0           re_lu_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 66, 66, 512)  1180160     max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 66, 66, 512)  2048        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_83 (ReLU)                 (None, 66, 66, 512)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 64, 64, 512)  2359808     re_lu_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 64, 64, 512)  2048        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_84 (ReLU)                 (None, 64, 64, 512)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 32, 32, 512)  0           re_lu_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 30, 30, 1024) 4719616     max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 30, 30, 1024) 4096        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_85 (ReLU)                 (None, 30, 30, 1024) 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 28, 28, 1024) 9438208     re_lu_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 28, 28, 1024) 4096        conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_86 (ReLU)                 (None, 28, 28, 1024) 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.resize (TFOpLambda)    (None, 56, 56, 512)  0           re_lu_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 56, 56, 1024) 4195328     re_lu_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 56, 56, 1536) 0           tf.image.resize[0][0]            \n",
      "                                                                 conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 54, 54, 512)  7078400     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 54, 54, 512)  2048        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_87 (ReLU)                 (None, 54, 54, 512)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 52, 52, 512)  2359808     re_lu_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 52, 52, 512)  2048        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_88 (ReLU)                 (None, 52, 52, 512)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.resize_1 (TFOpLambda)  (None, 104, 104, 256 0           re_lu_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 104, 104, 512 1049088     re_lu_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 104, 104, 768 0           tf.image.resize_1[0][0]          \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 102, 102, 256 1769728     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 102, 102, 256 1024        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_89 (ReLU)                 (None, 102, 102, 256 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 100, 100, 256 590080      re_lu_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 100, 100, 256 1024        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_90 (ReLU)                 (None, 100, 100, 256 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.resize_2 (TFOpLambda)  (None, 200, 200, 128 0           re_lu_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 200, 200, 256 262400      re_lu_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 200, 200, 384 0           tf.image.resize_2[0][0]          \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 198, 198, 128 442496      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 198, 198, 128 512         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_91 (ReLU)                 (None, 198, 198, 128 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 196, 196, 128 147584      re_lu_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 196, 196, 128 512         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_92 (ReLU)                 (None, 196, 196, 128 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.resize_3 (TFOpLambda)  (None, 392, 392, 64) 0           re_lu_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 392, 392, 128 65664       re_lu_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 392, 392, 192 0           tf.image.resize_3[0][0]          \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 390, 390, 64) 110656      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 390, 390, 64) 256         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_93 (ReLU)                 (None, 390, 390, 64) 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 388, 388, 64) 36928       re_lu_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 388, 388, 64) 256         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_94 (ReLU)                 (None, 388, 388, 64) 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 388, 388, 2)  130         re_lu_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 388, 388, 2)  8           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_95 (ReLU)                 (None, 388, 388, 2)  0           batch_normalization_99[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 36,973,898\n",
      "Trainable params: 36,962,118\n",
      "Non-trainable params: 11,780\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = 572,572,1\n",
    "nb_classes = 2\n",
    "m = UNet(nb_classes, input_shape)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d6877",
   "metadata": {
    "papermill": {
     "duration": 0.02352,
     "end_time": "2022-04-23T11:47:41.714454",
     "exception": false,
     "start_time": "2022-04-23T11:47:41.690934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **se_ResNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ed661c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:41.781837Z",
     "iopub.status.busy": "2022-04-23T11:47:41.780944Z",
     "iopub.status.idle": "2022-04-23T11:47:41.862304Z",
     "shell.execute_reply": "2022-04-23T11:47:41.861644Z",
     "shell.execute_reply.started": "2022-04-23T11:18:06.047210Z"
    },
    "papermill": {
     "duration": 0.122902,
     "end_time": "2022-04-23T11:47:41.862451",
     "exception": false,
     "start_time": "2022-04-23T11:47:41.739549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def se_ResNet50(input_w,input_h):\n",
    "  if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, input_w, input_h)\n",
    "  else:\n",
    "    input_shape = (input_w, input_h,3)\n",
    "\n",
    "  model_input = tf.keras.layers.Input(shape=input_shape)\n",
    " \n",
    "\n",
    "  ########### Block 1 ###########\n",
    "  block_1 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(model_input)\n",
    "  block_1 = tf.keras.layers.BatchNormalization()(block_1)\n",
    "  block_1 = tf.keras.layers.ReLU()(block_1)\n",
    "  block_1 = tf.keras.layers.MaxPooling2D(3, strides=2, padding='same')(block_1)\n",
    " ############ Block 2 #############\n",
    " ### conv_block ###\n",
    "  block_2_1 = tf.keras.layers.BatchNormalization()(block_1)\n",
    "  block_2_1 = tf.keras.layers.ReLU()(block_2_1)\n",
    "  block_2_1 = tf.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_1)\n",
    "  \n",
    "  block_2_1 = tf.keras.layers.BatchNormalization()(block_2_1)\n",
    "  block_2_1 = tf.keras.layers.ReLU()(block_2_1)\n",
    "  block_2_1 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_1)\n",
    "  \n",
    "  block_2_1 = tf.keras.layers.BatchNormalization()(block_2_1)\n",
    "  block_2_1 = tf.keras.layers.ReLU()(block_2_1)\n",
    "  block_2_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_1)\n",
    "\n",
    "  sh_cut_2 = tf.keras.layers.BatchNormalization()(block_1)\n",
    "  sh_cut_2 = tf.keras.layers.ReLU()(sh_cut_2)\n",
    "  sh_cut_2 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(sh_cut_2)\n",
    "\n",
    "  stg1_blok_2_1 = tf.keras.layers.add([sh_cut_2, block_2_1])\n",
    "  ### identity_block 1 ###\n",
    "  block_2_2 = tf.keras.layers.BatchNormalization()(stg1_blok_2_1)\n",
    "  block_2_2 = tf.keras.layers.ReLU()(block_2_2)\n",
    "  block_2_2 = tf.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_2)\n",
    "  \n",
    "  block_2_2 = tf.keras.layers.BatchNormalization()(block_2_2)\n",
    "  block_2_2 = tf.keras.layers.ReLU()(block_2_2)\n",
    "  block_2_2 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_2)\n",
    "  \n",
    "  block_2_2 = tf.keras.layers.BatchNormalization()(block_2_2)\n",
    "  block_2_2 = tf.keras.layers.ReLU()(block_2_2)\n",
    "  block_2_2 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_2)\n",
    "\n",
    "  stg1_blok_2_2 = tf.keras.layers.add([stg1_blok_2_1, block_2_2])\n",
    "\n",
    "  ### identity_block 2 ###\n",
    "  block_2_3 = tf.keras.layers.BatchNormalization()(stg1_blok_2_2)\n",
    "  block_2_3 = tf.keras.layers.ReLU()(block_2_3)\n",
    "  block_2_3 = tf.keras.layers.Conv2D(64,kernel_size=1,strides=1, padding='same')(block_2_3)\n",
    "  \n",
    "  block_2_3 = tf.keras.layers.BatchNormalization()(block_2_3)\n",
    "  block_2_3 = tf.keras.layers.ReLU()(block_2_3)\n",
    "  block_2_3 = tf.keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(block_2_3)\n",
    "  \n",
    "  block_2_3 = tf.keras.layers.BatchNormalization()(block_2_3)\n",
    "  block_2_3 = tf.keras.layers.ReLU()(block_2_3)\n",
    "  block_2_3 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_2_3)\n",
    "\n",
    "  stg1_blok_2_3 = tf.keras.layers.add([stg1_blok_2_2, block_2_3])\n",
    "\n",
    "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_2_3)\n",
    "  excitation = tf.keras.layers.Dense(units=256 / 16, activation='relu')(squeeze)\n",
    "  excitation = tf.keras.layers.Dense(256,activation='sigmoid')(excitation)\n",
    "  #excitation = tf.reshape(excitation, [-1,1,1,256])\n",
    "  scale = tf.keras.layers.multiply([stg1_blok_2_3, excitation])\n",
    "\n",
    "\n",
    "  block_1 = tf.keras.layers.BatchNormalization()(block_1)\n",
    "  block_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_1)\n",
    "\n",
    "  short_cut_2 = tf.keras.layers.add([scale, block_1])\n",
    "\n",
    "############ Block 3 #############\n",
    "  ### 1 : conv_block ###\n",
    "  block_3_1 = tf.keras.layers.BatchNormalization()(short_cut_2)\n",
    "  block_3_1 = tf.keras.layers.ReLU()(block_3_1)\n",
    "  block_3_1 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_1)\n",
    "  \n",
    "  block_3_1 = tf.keras.layers.BatchNormalization()(block_3_1)\n",
    "  block_3_1 = tf.keras.layers.ReLU()(block_3_1)\n",
    "  block_3_1 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_1)\n",
    "  \n",
    "  block_3_1 = tf.keras.layers.BatchNormalization()(block_3_1)\n",
    "  block_3_1 = tf.keras.layers.ReLU()(block_3_1)\n",
    "  block_3_1 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_1)\n",
    "\n",
    "  sh_cut_3 = tf.keras.layers.BatchNormalization()(short_cut_2)\n",
    "  sh_cut_3 = tf.keras.layers.ReLU()(sh_cut_3)\n",
    "  sh_cut_3 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(sh_cut_3)\n",
    "\n",
    "  stg1_blok_3_1 = tf.keras.layers.add([sh_cut_3, block_3_1])\n",
    "  ### 2 : identity_block  ###\n",
    "  block_3_2 = tf.keras.layers.BatchNormalization()(stg1_blok_3_1)\n",
    "  block_3_2 = tf.keras.layers.ReLU()(block_3_2)\n",
    "  block_3_2 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_2)\n",
    "  \n",
    "  block_3_2 = tf.keras.layers.BatchNormalization()(block_3_2)\n",
    "  block_3_2 = tf.keras.layers.ReLU()(block_3_2)\n",
    "  block_3_2 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_2)\n",
    "  \n",
    "  block_3_2 = tf.keras.layers.BatchNormalization()(block_3_2)\n",
    "  block_3_2 = tf.keras.layers.ReLU()(block_3_2)\n",
    "  block_3_2 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_2)\n",
    "\n",
    "  stg1_blok_3_2 = tf.keras.layers.add([stg1_blok_3_1, block_3_2])\n",
    "\n",
    "  ### 3 : identity_block  ###\n",
    "  block_3_3 = tf.keras.layers.BatchNormalization()(stg1_blok_3_2)\n",
    "  block_3_3 = tf.keras.layers.ReLU()(block_3_3)\n",
    "  block_3_3 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_3)\n",
    "  \n",
    "  block_3_3 = tf.keras.layers.BatchNormalization()(block_3_3)\n",
    "  block_3_3 = tf.keras.layers.ReLU()(block_3_3)\n",
    "  block_3_3 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_3)\n",
    "  \n",
    "  block_3_3 = tf.keras.layers.BatchNormalization()(block_3_3)\n",
    "  block_3_3 = tf.keras.layers.ReLU()(block_3_3)\n",
    "  block_3_3 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_3)\n",
    "  stg1_blok_3_3 = tf.keras.layers.add([stg1_blok_3_2, block_3_3])\n",
    "\n",
    " \n",
    "  \n",
    "\n",
    "  ### 4:identity_block  ###\n",
    "  block_3_4 = tf.keras.layers.BatchNormalization()(stg1_blok_3_3)\n",
    "  block_3_4 = tf.keras.layers.ReLU()(block_3_4)\n",
    "  block_3_4 = tf.keras.layers.Conv2D(128,kernel_size=1,strides=1, padding='same')(block_3_4)\n",
    "  \n",
    "  block_3_4 = tf.keras.layers.BatchNormalization()(block_3_4)\n",
    "  block_3_4 = tf.keras.layers.ReLU()(block_3_4)\n",
    "  block_3_4 = tf.keras.layers.Conv2D(128,kernel_size=3,strides=1,padding='same')(block_3_4)\n",
    "  \n",
    "  block_3_4 = tf.keras.layers.BatchNormalization()(block_3_4)\n",
    "  block_3_4 = tf.keras.layers.ReLU()(block_3_4)\n",
    "  block_3_4 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_3_4)\n",
    "\n",
    "  stg1_blok_3_4 = tf.keras.layers.add([stg1_blok_3_3, block_3_4])\n",
    "\n",
    "\n",
    "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_3_4)\n",
    "  excitation = tf.keras.layers.Dense(units=512 / 16, activation='relu')(squeeze)\n",
    "  excitation = tf.keras.layers.Dense(512,activation='sigmoid')(excitation)\n",
    "  #excitation = tf.reshape(excitation, [-1,1,1,512])\n",
    "  scale_3 = tf.keras.layers.multiply([stg1_blok_3_4, excitation])\n",
    "\n",
    "  short_cut_2 = tf.keras.layers.BatchNormalization()(short_cut_2)\n",
    "  short_cut_2 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(short_cut_2)\n",
    "\n",
    "  short_cut_3 = tf.keras.layers.add([scale_3, short_cut_2])\n",
    "\n",
    "\n",
    "\n",
    "  ############ Block 4 #############\n",
    "  ### 1 : conv_block ###\n",
    "  block_4_1 = tf.keras.layers.BatchNormalization()(short_cut_3)\n",
    "  block_4_1 = tf.keras.layers.ReLU()(block_4_1)\n",
    "  block_4_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_1)\n",
    "  \n",
    "  block_4_1 = tf.keras.layers.BatchNormalization()(block_4_1)\n",
    "  block_4_1 = tf.keras.layers.ReLU()(block_4_1)\n",
    "  block_4_1 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_1)\n",
    "  \n",
    "  block_4_1 = tf.keras.layers.BatchNormalization()(block_4_1)\n",
    "  block_4_1 = tf.keras.layers.ReLU()(block_4_1)\n",
    "  block_4_1 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_1)\n",
    "\n",
    "  sh_cut_4 = tf.keras.layers.BatchNormalization()(short_cut_3)\n",
    "  sh_cut_4 = tf.keras.layers.ReLU()(sh_cut_4)\n",
    "  sh_cut_4 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(sh_cut_4)\n",
    "\n",
    "  stg1_blok_4_1 = tf.keras.layers.add([sh_cut_4, block_4_1])\n",
    "\n",
    "  ### 2 :identity_block  ###\n",
    "  block_4_2 = tf.keras.layers.BatchNormalization()(stg1_blok_4_1)\n",
    "  block_4_2 = tf.keras.layers.ReLU()(block_4_2)\n",
    "  block_4_1 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_2)\n",
    "  \n",
    "  block_4_2 = tf.keras.layers.BatchNormalization()(block_4_2)\n",
    "  block_4_2 = tf.keras.layers.ReLU()(block_4_2)\n",
    "  block_4_2 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_2)\n",
    "  \n",
    "  block_4_2 = tf.keras.layers.BatchNormalization()(block_4_2)\n",
    "  block_4_2 = tf.keras.layers.ReLU()(block_4_2)\n",
    "  block_4_2 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_2)\n",
    "  stg1_blok_4_2 = tf.keras.layers.add([stg1_blok_4_1, block_4_2])\n",
    "\n",
    "  ### 3 : identity_block  ###\n",
    "  block_4_3 = tf.keras.layers.BatchNormalization()(stg1_blok_4_2)\n",
    "  block_4_3 = tf.keras.layers.ReLU()(block_4_3)\n",
    "  block_4_3 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_3)\n",
    "  \n",
    "  block_4_3 = tf.keras.layers.BatchNormalization()(block_4_3)\n",
    "  block_4_3 = tf.keras.layers.ReLU()(block_4_3)\n",
    "  block_4_3 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_3)\n",
    "  \n",
    "  block_4_3 = tf.keras.layers.BatchNormalization()(block_4_3)\n",
    "  block_4_3 = tf.keras.layers.ReLU()(block_4_3)\n",
    "  block_4_3 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_3)\n",
    "  stg1_blok_4_3 = tf.keras.layers.add([stg1_blok_4_2, block_4_3])\n",
    "\n",
    "  ### 4 : identity_block  ###\n",
    "  block_4_4 = tf.keras.layers.BatchNormalization()(stg1_blok_4_3)\n",
    "  block_4_4 = tf.keras.layers.ReLU()(block_4_4)\n",
    "  block_4_4 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_4)\n",
    "  \n",
    "  block_4_4 = tf.keras.layers.BatchNormalization()(block_4_4)\n",
    "  block_4_4 = tf.keras.layers.ReLU()(block_4_4)\n",
    "  block_4_4 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_4)\n",
    "  \n",
    "  block_4_4 = tf.keras.layers.BatchNormalization()(block_4_4)\n",
    "  block_4_4 = tf.keras.layers.ReLU()(block_4_4)\n",
    "  block_4_4 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_4)\n",
    "  stg1_blok_4_4 = tf.keras.layers.add([stg1_blok_4_3, block_4_4])\n",
    "\n",
    "  ### 5 : :identity_block  ###\n",
    "  block_4_5 = tf.keras.layers.BatchNormalization()(stg1_blok_4_4)\n",
    "  block_4_5 = tf.keras.layers.ReLU()(block_4_5)\n",
    "  block_4_5 = tf.keras.layers.Conv2D(256,kernel_size=1,strides=1, padding='same')(block_4_5)\n",
    "  \n",
    "  block_4_5 = tf.keras.layers.BatchNormalization()(block_4_5)\n",
    "  block_4_5 = tf.keras.layers.ReLU()(block_4_5)\n",
    "  block_4_5 = tf.keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(block_4_5)\n",
    "  \n",
    "  block_4_5 = tf.keras.layers.BatchNormalization()(block_4_5)\n",
    "  block_4_5 = tf.keras.layers.ReLU()(block_4_5)\n",
    "  block_4_5 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(block_4_5)\n",
    "  stg1_blok_4_5 = tf.keras.layers.add([stg1_blok_4_4, block_4_5])\n",
    "\n",
    "\n",
    "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_4_5)\n",
    "  excitation = tf.keras.layers.Dense(units=1024 / 16, activation='relu')(squeeze)\n",
    "  excitation = tf.keras.layers.Dense(1024,activation='sigmoid')(excitation)\n",
    "  #excitation = tf.reshape(excitation, [-1,1,1,1024])\n",
    "  scale_4 = tf.keras.layers.multiply([stg1_blok_4_5, excitation])\n",
    "\n",
    "\n",
    "  short_cut_3 = tf.keras.layers.BatchNormalization()(short_cut_3)\n",
    "  short_cut_3 = tf.keras.layers.Conv2D(1024,kernel_size=1,strides=1, padding='same')(short_cut_3)\n",
    "\n",
    "  short_cut_4 = tf.keras.layers.add([scale_4, short_cut_3])\n",
    "\n",
    "\n",
    "  ############ Block 5 #############\n",
    "  ### conv_block ###\n",
    "  block_5_1 = tf.keras.layers.BatchNormalization()(short_cut_4)\n",
    "  block_5_1 = tf.keras.layers.ReLU()(block_5_1)\n",
    "  block_5_1 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_1)\n",
    "  \n",
    "  block_5_1 = tf.keras.layers.BatchNormalization()(block_5_1)\n",
    "  block_5_1 = tf.keras.layers.ReLU()(block_5_1)\n",
    "  block_5_1 = tf.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_1)\n",
    "  \n",
    "  block_5_1 = tf.keras.layers.BatchNormalization()(block_5_1)\n",
    "  block_5_1 = tf.keras.layers.ReLU()(block_5_1)\n",
    "  block_5_1 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_1)\n",
    "\n",
    "  sh_cut_5 = tf.keras.layers.BatchNormalization()(short_cut_4)\n",
    "  sh_cut_5 = tf.keras.layers.ReLU()(sh_cut_5)\n",
    "  sh_cut_5 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(sh_cut_5)\n",
    "\n",
    "  stg1_blok_5_1 = tf.keras.layers.add([sh_cut_5, block_5_1])\n",
    "  ### identity_block 1 ###\n",
    "  block_5_2 = tf.keras.layers.BatchNormalization()(stg1_blok_5_1)\n",
    "  block_5_2 = tf.keras.layers.ReLU()(block_5_2)\n",
    "  block_5_2 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_2)\n",
    "  \n",
    "  block_5_2 = tf.keras.layers.BatchNormalization()(block_5_2)\n",
    "  block_5_2 = tf.keras.layers.ReLU()(block_5_2)\n",
    "  block_5_2 = tf.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_2)\n",
    "  \n",
    "  block_5_2 = tf.keras.layers.BatchNormalization()(block_5_2)\n",
    "  block_5_2 = tf.keras.layers.ReLU()(block_5_2)\n",
    "  block_5_2 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_2)\n",
    "\n",
    "  stg1_blok_5_2 = tf.keras.layers.add([stg1_blok_5_1, block_5_2])\n",
    "\n",
    "  ### identity_block 2 ###\n",
    "  block_5_3 = tf.keras.layers.BatchNormalization()(stg1_blok_5_2)\n",
    "  block_5_3 = tf.keras.layers.ReLU()(block_5_3)\n",
    "  block_5_3 = tf.keras.layers.Conv2D(512,kernel_size=1,strides=1, padding='same')(block_5_3)\n",
    "  \n",
    "  block_5_3 = tf.keras.layers.BatchNormalization()(block_5_3)\n",
    "  block_5_3 = tf.keras.layers.ReLU()(block_5_3)\n",
    "  block_5_3 = tf.keras.layers.Conv2D(512,kernel_size=3,strides=1,padding='same')(block_5_3)\n",
    "  \n",
    "  block_5_3 = tf.keras.layers.BatchNormalization()(block_5_3)\n",
    "  block_5_3 = tf.keras.layers.ReLU()(block_5_3)\n",
    "  block_5_3 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(block_5_3)\n",
    "\n",
    "  stg1_blok_5_3 = tf.keras.layers.add([stg1_blok_5_2, block_5_3])\n",
    "\n",
    "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(stg1_blok_5_3)\n",
    "  excitation = tf.keras.layers.Dense(units=2048 / 16, activation='relu')(squeeze)\n",
    "  excitation = tf.keras.layers.Dense(2048,activation='sigmoid')(excitation)\n",
    "  #excitation = tf.reshape(excitation, [-1,1,1,2048])\n",
    "  scale_5 = tf.keras.layers.multiply([stg1_blok_5_3, excitation])\n",
    "\n",
    "  short_cut_4 = tf.keras.layers.BatchNormalization()(short_cut_4)\n",
    "  short_cut_4 = tf.keras.layers.Conv2D(2048,kernel_size=1,strides=1, padding='same')(short_cut_4)\n",
    "\n",
    "  short_cut_5 = tf.keras.layers.add([scale_5, short_cut_4])\n",
    "############ Block 6 #############\n",
    "  \n",
    "  pooling = tf.keras.layers.GlobalAveragePooling2D()(short_cut_5)\n",
    "  #pooling = tf.keras.layers.Dense(5,activation='relu')(pooling)\n",
    "  model_output = tf.keras.layers.Dense(5,activation='softmax')(pooling)\n",
    "\n",
    "\n",
    "  model = tf.keras.models.Model(model_input,model_output)\n",
    " \n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d0d1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:47:41.919891Z",
     "iopub.status.busy": "2022-04-23T11:47:41.918650Z",
     "iopub.status.idle": "2022-04-23T11:47:43.595903Z",
     "shell.execute_reply": "2022-04-23T11:47:43.595098Z",
     "shell.execute_reply.started": "2022-04-23T11:18:14.734514Z"
    },
    "papermill": {
     "duration": 1.709555,
     "end_time": "2022-04-23T11:47:43.596054",
     "exception": false,
     "start_time": "2022-04-23T11:47:41.886499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 320, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 320, 256, 64) 1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 320, 256, 64) 256         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_96 (ReLU)                 (None, 320, 256, 64) 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 160, 128, 64) 0           re_lu_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 160, 128, 64) 256         max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_97 (ReLU)                 (None, 160, 128, 64) 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 160, 128, 64) 4160        re_lu_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 160, 128, 64) 256         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_98 (ReLU)                 (None, 160, 128, 64) 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 160, 128, 64) 36928       re_lu_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 160, 128, 64) 256         max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 160, 128, 64) 256         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_100 (ReLU)                (None, 160, 128, 64) 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_99 (ReLU)                 (None, 160, 128, 64) 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 160, 128, 256 16640       re_lu_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 160, 128, 256 16640       re_lu_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 160, 128, 256 0           conv2d_166[0][0]                 \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 160, 128, 256 1024        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_101 (ReLU)                (None, 160, 128, 256 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 160, 128, 64) 16448       re_lu_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 160, 128, 64) 256         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_102 (ReLU)                (None, 160, 128, 64) 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 160, 128, 64) 36928       re_lu_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 160, 128, 64) 256         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_103 (ReLU)                (None, 160, 128, 64) 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 160, 128, 256 16640       re_lu_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 160, 128, 256 0           add_19[0][0]                     \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 160, 128, 256 1024        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_104 (ReLU)                (None, 160, 128, 256 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 160, 128, 64) 16448       re_lu_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 160, 128, 64) 256         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_105 (ReLU)                (None, 160, 128, 64) 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 160, 128, 64) 36928       re_lu_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 160, 128, 64) 256         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_106 (ReLU)                (None, 160, 128, 64) 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 160, 128, 256 16640       re_lu_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 160, 128, 256 0           add_20[0][0]                     \n",
      "                                                                 conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 256)          0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           4112        global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          4352        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 160, 128, 64) 256         max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 160, 128, 256 0           add_21[0][0]                     \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 160, 128, 256 16640       batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 160, 128, 256 0           multiply[0][0]                   \n",
      "                                                                 conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 160, 128, 256 1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_107 (ReLU)                (None, 160, 128, 256 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 160, 128, 128 32896       re_lu_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 160, 128, 128 512         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_108 (ReLU)                (None, 160, 128, 128 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 160, 128, 128 147584      re_lu_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 160, 128, 256 1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 160, 128, 128 512         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_110 (ReLU)                (None, 160, 128, 256 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_109 (ReLU)                (None, 160, 128, 128 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 160, 128, 512 131584      re_lu_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 160, 128, 512 66048       re_lu_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 160, 128, 512 0           conv2d_177[0][0]                 \n",
      "                                                                 conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 160, 128, 512 2048        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_111 (ReLU)                (None, 160, 128, 512 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 160, 128, 128 65664       re_lu_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 160, 128, 128 512         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_112 (ReLU)                (None, 160, 128, 128 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 160, 128, 128 147584      re_lu_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 160, 128, 128 512         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_113 (ReLU)                (None, 160, 128, 128 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 160, 128, 512 66048       re_lu_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 160, 128, 512 0           add_23[0][0]                     \n",
      "                                                                 conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 160, 128, 512 2048        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_114 (ReLU)                (None, 160, 128, 512 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 160, 128, 128 65664       re_lu_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 160, 128, 128 512         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_115 (ReLU)                (None, 160, 128, 128 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 160, 128, 128 147584      re_lu_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 160, 128, 128 512         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_116 (ReLU)                (None, 160, 128, 128 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 160, 128, 512 66048       re_lu_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 160, 128, 512 0           add_24[0][0]                     \n",
      "                                                                 conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 160, 128, 512 2048        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_117 (ReLU)                (None, 160, 128, 512 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 160, 128, 128 65664       re_lu_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 160, 128, 128 512         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_118 (ReLU)                (None, 160, 128, 128 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 160, 128, 128 147584      re_lu_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 160, 128, 128 512         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_119 (ReLU)                (None, 160, 128, 128 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 160, 128, 512 66048       re_lu_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 160, 128, 512 0           add_25[0][0]                     \n",
      "                                                                 conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 512)          0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           16416       global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          16896       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 160, 128, 256 1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 160, 128, 512 0           add_26[0][0]                     \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 160, 128, 512 131584      batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 160, 128, 512 0           multiply_1[0][0]                 \n",
      "                                                                 conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 160, 128, 512 2048        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_120 (ReLU)                (None, 160, 128, 512 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 160, 128, 256 131328      re_lu_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 160, 128, 256 1024        conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_121 (ReLU)                (None, 160, 128, 256 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 160, 128, 256 590080      re_lu_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 160, 128, 512 2048        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 160, 128, 256 1024        conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_123 (ReLU)                (None, 160, 128, 512 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_122 (ReLU)                (None, 160, 128, 256 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 160, 128, 102 525312      re_lu_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 160, 128, 102 263168      re_lu_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 160, 128, 102 0           conv2d_191[0][0]                 \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 160, 128, 102 4096        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_124 (ReLU)                (None, 160, 128, 102 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 160, 128, 102 4096        re_lu_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_125 (ReLU)                (None, 160, 128, 102 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 160, 128, 256 2359552     re_lu_125[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 160, 128, 256 1024        conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_126 (ReLU)                (None, 160, 128, 256 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 160, 128, 102 263168      re_lu_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 160, 128, 102 0           add_28[0][0]                     \n",
      "                                                                 conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 160, 128, 102 4096        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_127 (ReLU)                (None, 160, 128, 102 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 160, 128, 256 262400      re_lu_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 160, 128, 256 1024        conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_128 (ReLU)                (None, 160, 128, 256 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 160, 128, 256 590080      re_lu_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 160, 128, 256 1024        conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_129 (ReLU)                (None, 160, 128, 256 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 160, 128, 102 263168      re_lu_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 160, 128, 102 0           add_29[0][0]                     \n",
      "                                                                 conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 160, 128, 102 4096        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_130 (ReLU)                (None, 160, 128, 102 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 160, 128, 256 262400      re_lu_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 160, 128, 256 1024        conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_131 (ReLU)                (None, 160, 128, 256 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 160, 128, 256 590080      re_lu_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 160, 128, 256 1024        conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_132 (ReLU)                (None, 160, 128, 256 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 160, 128, 102 263168      re_lu_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 160, 128, 102 0           add_30[0][0]                     \n",
      "                                                                 conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 160, 128, 102 4096        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_133 (ReLU)                (None, 160, 128, 102 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 160, 128, 256 262400      re_lu_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 160, 128, 256 1024        conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_134 (ReLU)                (None, 160, 128, 256 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 160, 128, 256 590080      re_lu_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 160, 128, 256 1024        conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_135 (ReLU)                (None, 160, 128, 256 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 160, 128, 102 263168      re_lu_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 160, 128, 102 0           add_31[0][0]                     \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 1024)         0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           65600       global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1024)         66560       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 160, 128, 512 2048        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 160, 128, 102 0           add_32[0][0]                     \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 160, 128, 102 525312      batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 160, 128, 102 0           multiply_2[0][0]                 \n",
      "                                                                 conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 160, 128, 102 4096        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_136 (ReLU)                (None, 160, 128, 102 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 160, 128, 512 524800      re_lu_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 160, 128, 512 2048        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_137 (ReLU)                (None, 160, 128, 512 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 160, 128, 512 2359808     re_lu_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 160, 128, 102 4096        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 160, 128, 512 2048        conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_139 (ReLU)                (None, 160, 128, 102 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_138 (ReLU)                (None, 160, 128, 512 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 160, 128, 204 2099200     re_lu_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 160, 128, 204 1050624     re_lu_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 160, 128, 204 0           conv2d_208[0][0]                 \n",
      "                                                                 conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 160, 128, 204 8192        add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_140 (ReLU)                (None, 160, 128, 204 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 160, 128, 512 1049088     re_lu_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 160, 128, 512 2048        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_141 (ReLU)                (None, 160, 128, 512 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 160, 128, 512 2359808     re_lu_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 160, 128, 512 2048        conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_142 (ReLU)                (None, 160, 128, 512 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 160, 128, 204 1050624     re_lu_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 160, 128, 204 0           add_34[0][0]                     \n",
      "                                                                 conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 160, 128, 204 8192        add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_143 (ReLU)                (None, 160, 128, 204 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 160, 128, 512 1049088     re_lu_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 160, 128, 512 2048        conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_144 (ReLU)                (None, 160, 128, 512 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 160, 128, 512 2359808     re_lu_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 160, 128, 512 2048        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_145 (ReLU)                (None, 160, 128, 512 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 160, 128, 204 1050624     re_lu_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 160, 128, 204 0           add_35[0][0]                     \n",
      "                                                                 conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          262272      global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2048)         264192      dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 160, 128, 102 4096        add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 160, 128, 204 0           add_36[0][0]                     \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 160, 128, 204 2099200     batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 160, 128, 204 0           multiply_3[0][0]                 \n",
      "                                                                 conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 2048)         0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 5)            10245       global_average_pooling2d_6[0][0] \n",
      "==================================================================================================\n",
      "Total params: 27,443,317\n",
      "Trainable params: 27,395,957\n",
      "Non-trainable params: 47,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_w = 320\n",
    "image_h = 256\n",
    "n_classes = 5\n",
    "model = se_ResNet50(image_w,image_h)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.683551,
   "end_time": "2022-04-23T11:47:46.733869",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-23T11:47:18.050318",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
